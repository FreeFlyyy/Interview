一、java se
	1.反序列化的类名
		序列化的时候，会将对象的类信息放在序列化的字节中，方便在反序列化时加载相关相关的类。
	2.HashMap
		a).初始的capacity大小
			16，并且HashMap的桶容量始终为2^n，主要是为了求余的方便。
		b).扩容机制
			HashMap中有一个loadFactor，当hashmap当前的元素个数达到了capacity*loadFactory时，便会增加桶的个数。
			桶的个数增加，之前桶里的数据需要重新放置在新的桶中。更进一步的说，这样的机制可以保证桶中的元素不至于过多，而导致链表搜索时间过长。
	3.TreeMap
		a).为什么要用红黑树
			插入删除的旋转次数更少，即效率更高。
	4.为什么要重载equal方法？
		因为Object的equal方法默认是两个对象的引用的比较，意思就是指向同一内存,地址则相等，否则不相等；如果你现在需要利用对象里面的值来判断是否相等，则重载equal方法。
	5.为什么重载hashCode方法
	  一般的地方不需要重载hashCode，只有当类需要放在HashTable、HashMap、HashSet等等hash结构的集合时才会重载hashCode
	6.java继承方法调用顺序：
		如果b类继承自a类，在main方法中new出b的对象(不带参数)，那么他执行的顺序是：	
			父类a的类变量赋值-->父类a的静态代码块-->类b的类变量赋值-->类b的静态代码块-->父类a的非静态代码块-->父类a的无参构造函数-->子类b的非静态代码块-->子类b的无参构造函数
	7.String、StringBuilder、StringBuffer三者的作用
		String是一个不可变对象，其任何方法都不会给对象的状态带来修改。有一些方法生成新的String。
		StringBuilder是一个可变的对象，在字符串操作上更为灵活。
		StringBuffer和StringBuilder基本相同，但是其方法引入了Synchronized，因此StringBuffer是一个线程安全类，而StringBuilder并非是线程安全类。
		由于StringBuffer大量使用了Synchronized，因此单线程情况下StringBuilder的效率将会高于StringBuffer。
二、java ee
	1.DispatchServlet流程
		a).通过请求从handlermapping中获取对应的控制器和拦截器链，mappedHandler = getHandler(processedRequest);
		b).使用handlerAdapter封装控制器，HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());
		c).拦截器链处理，mappedHandler.applyPreHandle(processedRequest, response)
		d).执行控制器，得到mv。mv = ha.handle(processedRequest, response, mappedHandler.getHandler());
		e).拦截器处理，applyPostHandle。
		f).主要是对结果mv进行处理，渲染视图。processDispatchResult。
	2.spring aop
		生成代理：通过AopProxyFactory生成代理对象；默认策略是目标类是接口，则使用JDK动态代理，否则使用Cglib。
		织入：获取可以应用到此方法上的通知链（Interceptor Chain）,如果有,创建MethodInvocation，调用其proceed方法，触发拦截器链的执行,并执行joinpoint; 如果没有,则直接反射执行joinpoint。
	3.SpringMVC和Struts2的区别
	4.Spring如何解决循环依赖
		让我们来分析一下“A的某个field或者setter依赖了B的实例对象，同时B的某个field或者setter依赖了A的实例对象”这种循环依赖的情况。A首先完成了初始化的第一步，
		并且将自己提前曝光到singletonFactories中，此时进行初始化的第二步，发现自己依赖对象B，此时就尝试去get(B)，发现B还没有被create，所以走create流程，B在
		初始化第一步的时候发现自己依赖了对象A，于是尝试get(A)，尝试一级缓存singletonObjects(肯定没有，因为A还没初始化完全)，尝试二级缓存earlySingletonObjects（也没有），
		尝试三级缓存singletonFactories，由于A通过ObjectFactory将自己提前曝光了，所以B能够通过ObjectFactory.getObject拿到A对象(虽然A还没有初始化完全，但是总比没有好呀)，
		B拿到A对象后顺利完成了初始化阶段1、2、3，完全初始化之后将自己放入到一级缓存singletonObjects中。此时返回A中，A此时能拿到B的对象顺利完成自己的初始化阶段2、3，
		最终A也完成了初始化，长大成人，进去了一级缓存singletonObjects中，由于B拿到了A的对象引用，所以B现在hold住的A对象也蜕变完美了！
	5.Spring配置相关
		1.让spring识别@Scheduled注解  <task:annotation-driven />                                  
		2.定时1s @Scheduled(cron = "0/1 * * * * ?")
		3.<mvc:default-servlet-handler />将静态资源的处理经由Spring MVC框架交回Web应用服务器处理
		4.<mvc:resources />由Spring MVC框架自己处理静态资源
		5.@Transactional配置事务
	6.Spring的事务传播级别
		1） PROPAGATION_REQUIRED ，默认的spring事务传播级别，使用该级别的特点是，如果上下文中已经存在事务，那么就加入到事务中执行，如果当前上下文中不存在事务，
			则新建事务执行。
		2）PROPAGATION_SUPPORTS ，如果上下文存在事务，则支持事务加入事务，如果没有事务，则使用非事务的方式执行。
		3）PROPAGATION_MANDATORY ， 该级别的事务要求上下文中必须要存在事务，否则就会抛出异常！
		4）PROPAGATION_REQUIRES_NEW ，每次都会新建一个事务，并且同时将上下文中的事务挂起，执行当前新建事务完成以后，上下文事务恢复再执行。
		5）PROPAGATION_NOT_SUPPORTED ，这当前级别的特点就是上下文中存在事务，则挂起事务，执行当前逻辑，结束后恢复上下文的事务。
		6）PROPAGATION_NEVER ，PROPAGATION_NEVER传播级别要求上下文中不能存在事务，一旦有事务，就抛出runtime异常，强制停止执行！
		7）PROPAGATION_NESTED ，该传播级别特征是，如果上下文中存在事务，则嵌套事务执行，如果不存在事务，则新建事务。
	7.spring ioc实现原理
		IoC分了两层实现，现在以两个IoC产品为例：
			- DefaultListableBeanFactory
				这个是一个最基本的beanFactory产品，并且也只负责管理bean。若要使用该BeanFactory需要额外使用Resource来定位资源，使用Reader来解析并加载。
			- FilSystemXmlApplicationContext
				该产品具备比BeanFactory更高级的功能，集合了资源定位，解析资源，注册BeanDefinition等功能。
				该类通过继承ResourceLoader来提供资源定位能力，通过具备生成Reader来解析资源，并且在将资源解析为BeanDefinition后将其注册到map中。
三、oop
	1.面向对象设计的solid原则
		1).单一责任原则(Single responsibility)
			一个类的职责为一个，也只有这个原因会造成类的修改。当类需要承担其他责任时，应该分解该类。
		2).开闭原则(Open close)
			类应该是对扩展开放，对修改封闭的。
		3).里式替换原则(Liskov Substitution)
			子类和父类是is-A关系。
		4).接口分离原则(Interface Segregation)
			面向接口编程。
		5).依赖倒置原则(Dependency Inversion)
			高层模块不应该依赖于底层模块，二者都应该依赖于抽象。
			抽象不应该依赖细节，细节需要依赖抽象。
	2.哪些框架里面用过装饰器模式
		Stream
	3.哪些框架里面用过工厂模式(包括抽象工厂和工厂方法)？
		Spring(抽象工厂)、线程池，数据库连接池。
	4.为什么要使用工厂模式
	5.简单工厂和抽象工厂的区别
	6.面向过程和面向对象的区别
四、jvm
	1.新生代gc的原理(Minor GC)
		新生代gc采用复制-清除算法。jvm给新生代分配了3块空间:survivor1, survivor2, Eden.
		新生对象放置在Eden空间中，当Eden满时将会把Eden和survivor中幸存的对象复制到另一个survivor中，然后将Eden清空。每次经过一次Minor GC将会使仍然幸存的对象年龄加一，达到一定年龄的对象将会转到老年代空间。
	2.full gc的触发时机和原理
		a).System.gc();建议jvm进行full gc，但是并不是立即执行。
		b).当Minor GC发生时，将会保存仍然幸存的对象，当仍然幸存的对象过大时，会向老年代空间申请空间，若老年代空间不够用了，会触发full gc。若仍然不够，则抛出异常。
		c).分配大对象时，会将大对象直接保存到老年代中，若老年代空间不够，会触发一次full gc。
	3.类加载流程
		1).加载，读取class的二进制数据，在内存中。
		2).验证，保证Class文件的字节流包含的信息符合JVM规范，不会给JVM造成危害。
		3).准备，为变量分配内存，并设置类变量的初始化。
		4).解析，将里面可以解析的符号进行解析。
		5).初始化，执行类中static域的赋值和static方法。
	4.如何热替换
		需要利用classloader。
		简单来说，在加载一个类时，需要使用用户自定义类加载器UserClassLoader来进行加载。修改了类的代码后，需要通过字节码生成技术重新生成类的class文件，然后舍去之前的类加载器，并新建一个UserClassLoader来进行加载。以前加载进来的类和类加载器将会被从内存中移除。
		参考jsp的class实时加载方案，每个jsp都将生成对应的java文件并会生成对应的字节码class文件，每个jsp-class文件都会用JasperLoader进行类加载，当jsp-class被修改会新建一个JasperLoader来加载新的jsp-class，而丢弃以前的。
	5.各类引用
		强引用， 是指创建一个对象并把这个对象赋给一个引用变量。强引用有引用变量指向时永远不会被垃圾回收。即使内存不足的时候。
		软引用，当内存空间不足的时候，引用的对象才会gc标记并且清楚。
		弱引用，引用的对象只能活到下次gc。
		虚引用，为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知。
	6.同类名不同jar包的类加载
		jvm 加载包名和类名相同的类时，先加载classpath中jar路径放在前面的，包名类名都相同，那jvm没法区分了，如果使用ide一般情况下是会提示发生冲突而报错，
		若不报错，只有第一个包被引入（在classpath路径下排在前面的包），第二个包会在classloader加载类时判断重复而忽略。
	7.一个大量对象迅速产生又死亡的代码如何优化
五、编程 数据结构与算法
	1.选择法排序
		基本思想是 每次遍历数组选择最小的值，然后将该值放到最前面。
		更进一步，第i次遍历，选择r[i+1]~r[n-1]中的最小值，并与r[i]进行交换，直至全部完毕。
	2.外部排序
		磁盘中可以存储的数据远大于内存，为了对磁盘中的海量数据进行排序，因此要使用外部排序。这里设内存可以放置的数据元素为N个。
		1).简单算法(两路合并)
			读取N个数据到内存中，进行排序并输出到磁盘中。这样可以将磁盘中的数据分为M组，每组N个元素的顺串保存到磁盘中。
			然后可以进行顺串的合并，两两长度为N的顺串合并后得到M/2组长度为2*N的顺串，按同样的方法再次进行排序，直到只有1组顺串为止。
			顺串合并采用归并排序是所用的合并方案。
		2).多路合并
			借鉴上述的方案，在得到初始的M组顺串后，使用k组顺串合并的方案，这样可以减少合并的次数，但是为了得到k个数的最小值会比2路的多花些时间。
		3).多相合并
			多相合并主要是为了节约磁盘空间。不展开。
		4).替换选择
			多路合并的方案需要读入N个元素到内存，然后输出一个长度为N的顺串。后面的合并操作主要受顺串的个数影响。
			为了进一步减小顺串的个数，可以考虑增大一个顺串的长度。
			N个元素读入到内存中并建立一个优先队列，执行一次deleteMin，把最小的元素输出到磁盘中。然后再读入一个元素到内存，若是比刚刚输出的元素大则将其入堆，若是比刚刚的输出元素小，则让它进死区，因为刚刚已经输出了比这个元素大的了，不能输出新加入的元素到磁盘中。
			一直如此，直到队列中没有元素时，便输出了一个顺串。此时死区已满，将死区中的数据重建堆，进行新的顺串输出。
	3.快速排序
		c++的stl采用的排序方法。
		基本思想是选取数组中的一个数，称为枢纽元。将数组中比枢纽元小的数分为1组，比枢纽元大的数分为1组，然后将这两组排序。排序得到两组数，可以直接拼接得到最终排序结果。
		枢纽元的选取方案；三数中值分割法，即选取左端 右端 中心位置上的3个元素的中值作为枢纽元。
	4.最长公共子序列
		最大公共子序列有这么一个特点：两串的结尾符号相同时，那么该符号必定是最大公共子序列的结尾符号。
		设c[i, j]为x1...xi和y1...yj的最大公共子序列的长度，那么：有
		c[i, j] = 0								, if i=0 or j=0
		        = c[i-1, j-1] + 1				, if xi==xj
				= max( c[i-1, j], c[j, i-1] )	, if i,j>0 and xi!=xj
	5.反向链表
		1).递归方案
			Node process(Node parent){
				if(this.next != null){
					Node node = this.next.process(this);	//记录反转后的首节点
					this.next=parent;
					return node; 
				}else{
					this.next=parent;
					return this;
				}
			}
		2).三指针方案
			第一个指针指向当前节点的父节点，第二个指针指向当前节点，第三个指针指向下一个节点，修改第二个指针的节点的next的指向到第一个指针的节点。滑动这3个指针。
	6.数组中最的子数组之和
	7.有一个生成0/1的随机数生成器，生成0的概率是p，生成1的概率是1-p，基于此设计一个随机数生成器，使得产生0/1的概率均为1/2
	8.一个数组中包含了1到1w的不重复数字，找出该数组中不存在的1到1w的两个数字。
	10.计算字符串表达式的值
	11.01背包问题
六、linux
	1.awk命令
		awk是一个强大的文本分析工具。awk将文件逐行读取，以空格为默认的分隔符将每行切片，对切开的部分再进行分析处理。
		相当于awk每次输入的是文本的一行的多个切片，切片之间默认以是原始行字符串进行空格分割得到的。
		awk [选项参数] '<script>' <filename>
		<filename>为要处理的文件
		[选项参数] 是一些awk处理的配置，如设置分隔符，可省。
		这里的<script>的格式为: '{[pattern] <action>}'，这里的[pattern]相当于是个正则匹配，对一行的切片进行一个筛选，可省。action是对一行的切片进行具体的处理。
		如：awk '{print $1,$4}' log.txt， 这里<filename>为log.txt，<action>为print $1, $4。 $1和$4就是对切片的引用，切片的下标从【1】开始。
	2.无法删除文件的原因
		没有写权限。
	3.查看服务器状态
		cat /proc/cpuinfo          查看cpu信息，如每个CPU型号，主频等
		free                       查看内存使用情况
		cat /proc/meminfo          查看详细内存使用情况
		lsblk                      查看硬盘和分区
		lspcl | grep -i 'eth'      查看网卡硬件信息
		ifconfig                       
		netstat -a (all)显示所有选项，默认不显示LISTEN相关
				-t (tcp)仅显示tcp相关选项
				-u (udp)仅显示udp相关选项
				-n 拒绝显示别名，能显示数字的全部转化成数字。
				-l 仅列出有在 Listen (监听) 的服務状态
				-p 显示建立相关链接的程序名
				-r 显示路由信息，路由表
				-e 显示扩展信息，例如uid等
				-s 按各个协议进行统计
				-c 每隔一个固定时间，执行该netstat命令。
		top     top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；
		
七、计算机网络
	1.三次握手
		第一次
		第一次握手：建立连接时，客户端发送syn包（syn=j）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。
		第二次
		第二次握手：服务器收到syn包，必须确认客户的SYN（ack=j+1），同时自己也发送一个SYN包（syn=k），即SYN+ACK包，此时服务器进入SYN_RECV状态；
		第三次
		第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。
	2.四次挥手
		A发起FIN关闭请求，A端进入FIN_WAIT_1状态。
		B端收到FIN请求后回应ACK, A端进入FIN_WAIT_2状态，B端进入CLOSE_WAIT状态。
		B发起FIN请求，B端进入LAST_ACK状态。
		A端收到FIN请求后回应ACK，A端进入TIME_WAIT等待一段时间后，将进行关闭，B端收到ACK将关闭。
	3.TCP和UDP的区别
		1).TCP
			TCP会进行三次握手和四次握手以确定连接成功。
			对于数据的发送，会将数据缓存，若发送超时会将缓存的数据重新进行发送。
		2).UDP
			UDP不会将待发送数据缓存，而是直接发送出去。UDP速度快，但是可靠性不及TCP。
	4.TCP有哪些确保连接的机制
		1).三次握手 四次挥手
		2).滑动窗口机制协商队列大小实现数据传输
		3).超时重传
		4).CRC校验
		5).对于收到的请求，会进行回应
		6).顺序编号(确保消息顺序)
	5.HTTP头包含哪些内容
		1).请求头常见信息
			Accept-Charset，用于指定客户端接受的字符集
			Accept-Encoding，用于制定客户端可接受的编码
			Accept-Language，用于指定客户端可接受的语言
			Host，请求资源的Internet主机域名和端口号
			User-Agent，客户端的操作系统，浏览器和其他属性告诉服务器
			Connection，当前连接是否需要保持(开启后便是长连接，http服务不会重新发起连接而是使用已经存在的)
			Cookie，保存在浏览器的cookie数据
		2).响应头
			Server，服务器使用的http服务器名称
			Content-Type，告诉浏览器实体正文的内容类型(如json html)
			Content-Encoding，告诉浏览器服务端所采用的压缩编码方式
			Content-Length，告诉浏览器实体正文的长度
			Keep-Alive，告诉浏览器保持连接的时间
	6.http状态码(200 301 302 403 404 500)
		100-199 用于指定客户端应相应的某些动作。 
		200-299 用于表示请求成功。 
		300-399 用于已经移动的文件并且常被包含在定位头信息中指定新的地址信息。 
		400-499 用于指出客户端的错误。 
		500-599 用于支持服务器错误。 
		
		200 : 请求已经成功。
		301 : 重定向。
		302 : 请求的资源现在临时从不同的 URI 响应请求。也是一个重定向。
		403 : 服务器已经理解请求，但是拒绝执行它。
		404 : 请求失败，请求所希望得到的资源未被在服务器上发现。
		500 : 服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。
	7.HTTPS
		https是一种结合了对称加密+非对称加密+第三方公证的技术。
		采用对称加密，可以防止在网络传输中数据被窃取，但是对称加密需要分享密钥，这不仅存在安全问题，并且多个网站采用的密钥可能不同，因此都需要分享密钥，存在较大的安全隐患。
		采用非对称加密，便于安全的分享密钥。客户端通过服务器端的公钥进行加密，服务器端收到数据将由其私钥进行解密。但是非对称加密的加密速度较慢。
		采用对称+非对称加密的方式，对称加密用于加密实际的文件内容，非对称加密用来传输对称加密需要用的密钥。但是存在中间人攻击的漏洞。
		中间人攻击：
			A和B通过非对称加密来进行共享数据，C为中间人。
			A发出去的公钥被C截获，C将自己生成的公钥发送给B，B以为该公钥是A的公钥并将数据进行加密传输给A。B的加密数据被C截获并被C的私钥解密。
			中间人攻击的本质是采用公钥进行加密的一方，不能确保公钥所属的安全性。
		通过第三方提供公证的方式来提供一个安全的公钥：
			提供方式的是每个服务器端都会将自己的公钥交给公证处。
			公证处记录了每个https服务器的公钥机及其基本信息，并会通过hash算法为每个https服务器生成一个消息摘要，并通过CA的私钥对消息摘要进行加密得到数字签名。
			https服务器的公钥，基本信息，及其数字签名，被称为该https服务器的【数字证书】。
			之所以要将消息摘要加密生成数字签名，是为了避免中间人自己生成一个伪造公钥的消息摘要，因此对消息摘要进行加密。
			客户端将https服务器的公钥和基本信息进行hash，并将数字签名通过CA的公钥进行解密，看看两个消息摘要是否相同，若相同则可以信任，公钥安全。
			CA的公钥一开始就已经嵌入到了浏览器或是操作系统内部了。
		具体流程：
			客户端发出https请求，
			服务器接收到https，并返回客户端数字证书，
			客户端通过内置的CA公钥验证数字证书是否正确，
			客户端生成一个随机的密钥用于对称加密，通过数字证书中的public key将该数据进行加密并发送给服务器，
			服务器用自己的RSA的private key得到对称加密的密钥，
			以后的数据传输通过该密钥进行。
	8.DNS的原理
		用于解析域名所对应的ip。
		1).浏览器会检查缓存中有没有这个域名解析过IP，如果有直接使用。浏览器域名缓存有大小和时间限制。
		2).浏览器中没有，就会到操作系统的hosts配置文件中查找对应的ip。linux下为/etc/hosts
		3).配置文件中没有，就会到域名服务器中查询，域名服务器为本机的网络配置中的DNS服务器地址。该域名服务器也称为本地DNS服务器(LDNS)。该解析器会缓存域名解析结果，大部分的解析工作在这里就能完成。
		4).LDNS中也没有查找到，LDNS将会到Root Server域名服务器请求解析。Root Server返回LDNS一个所查询域名的主域名服务器(gTLD Server)。gTLD全球只有13台左右，如.com .net等等各自的总域名服务器。
		5).LDNS将会到gTLD Server中查询Name Server域名服务器。Name Server就是该域名注册的服务器，例如在腾讯云的域名提供商申请的域名，那么就有这个域名提供商的服务器来完成解析。
		6).LDNS将会到Name Server中查询，并得到最后的结果。(Name Server可能有多级，因此可能会有多次查询才能得到结果)
		7).将结果返回给本地主机。
	9.cookie、session
		1).cookie
			将和服务器交互的数据保存在浏览器中。数据量过大时，会增大传输延迟。
		2).session
			客户的数据保存在服务器，通过cookie中的sessionid来让服务器知道当前的请求来自哪个浏览器。通常是保存在内存当中。数据量过大时会增大服务器压力。
			因为cookie的数据保存在本地，容易受到编辑，因此session常用来保存一些安全级别较高的数据，比如用户的认证信息等。
		3).session的生命周期
			- 打开浏览器，在浏览器上发送首次请求
			- 服务器会创建一个HttpSession对象，该对象代表一次会话
			- 同时生成HttpSession对象对应的Cookie对象，并且Cookie对象的name是JESSIONID，cookie的value是32位长度的字符串
			- 服务器将cookie 的value和HttpSession对象绑定到session列表中
			- 服务器将cookie发送到浏览器客户端，并且浏览器将cookie保存到缓存中
			- 只要浏览器不关闭，cookie不会消失
			- 当再次发送请求时，浏览器会自动提交缓存当中的cookie给服务器
			- 服务器收到cookie，验证该cookie的name确实是：JESSIONID，然后获取该cooike的value
			- 通过cookie的value去session列表中检索对应的HttpSession对象。
	10.TCP的流量控制和拥塞控制
		1).概念
			流量控制是由于接收方进程对socket缓冲区的读取速度太慢，造成socket缓冲区渐满，因此需要抑制发送方的发送速度。
			拥塞控制是由于发送方发送的速度过快，导致后面的路由器缓冲溢出造成后面接收到的包被丢弃，因此导致丢包问题，因此需要抑制发送方的速度。
		2).机制
			发送方和接收方都分别维护了滑动窗口。发送方维护了rwnd窗口，接收方维护rwnd。
			rwnd用于流量控制，cwnd用于拥塞控制。
			实际控制的窗口其实是发送方的cwnd和rwnd，即：LastByteSent - LastByteAcked <= min(cwnd, rwnd)
			该发送的策略是：当未确认的字节数小于最小窗口时，可以继续发送数据，否则终止发送。
			确定了发送策略， 再来确定rwnd和cwnd的变化策略。
			a).流量控制
				在接收端维护了两个变量：rwnd = LastByteRcvd-LastByteRead = 最后接收到字节序号 - 最后读出的直接序号 = 缓冲区中还可以存放的字节数
				该变量让接收端始终能够知道缓冲区的大小，并且在响应发送方时会将rwnd放入报文段中通知发送方。发送方将获悉接收方的rwnd。
				虽然发送方没有维护rwnd，但是其实他一直都知道rwnd的值。
				当rwnd为0时，避免发送方无法察觉rwnd不为0的时刻，所以此时会间断发送1字节数据以获取接收方的ack中的rwnd。
			b).拥塞控制
				- 慢启动
					在起初，发送方的cwnd为1，每个MSS接收到ack时会将cwnd+MSS。
					其实该方法的cwnd的增大速度是比较快的，因为会很快发送cwnd/MSS个包，因此若未拥塞则会接收到cwnd/MSS个ack，也就是会让cwnd指数增长。
					当包超时意味着发生了拥塞，此时将ssthresh=cwnd/2; cwnd=1，此时进入拥塞避免模式;
					当接收到3个冗余ACK意味拥塞，此时进入快速恢复模式。
				- 拥塞避免
					接收到一个MSS的ACK时会将cwnd增加MSS/cwnd。当cwnd增加到ssthresh时，重新进入慢启动模式。
					当包超时意味着发生了拥塞，此时将ssthresh=cwnd/2; cwnd=1，此时进入拥塞避免模式;
					当接收到3个冗余ACK意味拥塞，此时进入快速恢复模式。
				- 快速恢复
					接收到冗余ACK，将cwnd=cwnd+MSS。
					当接收到行的ACK，意味着非阻塞，此时转换到拥塞避免模式。
					当包超时意味着发生了拥塞，此时将ssthresh=cwnd/2; cwnd=1，此时进入拥塞避免模式;
	11.超时重传：
		基本原理：在发送一个数据之后，就开启一个定时器，若是在这个时间内没有收到发送数据的ACK确认报文，则对该报文进行重传，在达到一定次数还没有成功时放弃并发送一个复位信号。 
	12.快速重传：	
		如果发送端接受到3个以上的重复ACK的情况下，就应该意识到，数据丢了，需要重新传递。这个机制是不需要等到重传定时器溢出的，所以叫做快速重传
	11.连接一个网址涉及到的操作
		1).应用层(http)
			- dns，基于TCP实现。
			- cdn，内容分发网络，将网站的静态资源发布到各个cdn服务器，用户获取这些资源的时候将会到最近的服务器去获取，以提高用户访问网站的速度。静态数据以css，js图片，html为主。
			- http，无状态短链接传输协议，将请求头(多个请求行组成)和请求体发送过去，并等待响应(响应头和响应体)
		2).传输层处理(tcp)
			在应用层确定发送域名的ip后(应用层的dns服务)以及需要传输的数据(http数据)，就能通过tcp协议和服务器端的tcp监听socket进行连接了。
			连接采用3次握手，当连接成功时，本地就能通过socket将这些数据发送到服务器端，服务器端也可以发送数据到客户端。
			当连接结束时，将会通过4次挥手断开。
		3).网络层处理(ip)
			解析从当前计算机经过哪些路由器才能到服务器所在的主机。
		4).链路层处理(arp)
			当到了服务器所连接的路由器时，将会通过arp来找到具体的主机ip对应的mac地址，将数据交由对应的主机。
			arp机制:
				每台主机都会在内存中建立一个ARP列表，以表示IP地址和MAC地址的对应关系。
				当源主机需要将数据发送给目标主机时，会首先检查自己ARP列表是否有这个IP对应的MAC，有则直接发送。
				否则发起ARP广播包，该包中包含了源主机地址(mac, ip)以及目标的ip，网络中的所有主机收到该包后会检查目标ip和自己是否一致，若不一致则不做回应。
				和目标ip一致的主机将会刷新下自己的ARP列表(更新源主机ip对应的mac)，然后返回自己的mac给源主机，源主机更新ARP，再传送数据。
	12.PUT通常指定了资源的存放位置，POST的数据存放位置由服务器自己决定
	13.time_wait的原因，大量time_wait的场景以及解决，以及状态占用的资源。
		原因：time_wait是tcp发起关闭的一方，会进入time_wait状态， 持续2*MSL(缺省为240s)如果没有收到来自另一方的数据，才真正的关闭连接。
		场景：Http场景下就会在服务器里出现大量的time_wait
			服务器中若存在大量的time_wait，会造成端口号被占用，进而造成服务器端口号不够分配 后续连接失败。
			- 短连接
				短连接是每个http请求都使用一个tcp连接，而服务器为了保证自身内存的最优，因此在短连接结束后是由服务器发起关闭的。
				也因此短连接的高并发场景下，服务器容易积累大量的time_wait。
			- nginx反向代理
				负载均衡的场景下大量使用nginx服务器，而该nginx和后端服务器的连接采用短连接，因此会造成后端服务器可能会产生大量的time_wait。
			- 解决
				* 采用长连接的方式
					该方式下双方都可能主动断开连接。客户端关闭的时候，可以由客户端发起关闭。连接长时间没有被使用，则由服务器端发起关闭。
					即客户端的请求里面Connection头为keepAlive，通知服务器保持连接。直到超时服务器关闭连接， 或是发送close告知服务器本次断开连接。
					也可以将nginx连接后端的方式改为长连接。
				* 配置
					time_wait的时间默认为4分钟，减少time_wait的时间即可。
					socket配置SO_REUSEADDR，可以让socket使用time_wait中的端口号。
					配置socksetopt，处于time_wait的socket的端口号可以被立即重用。
					配置recycle，来快速回收被关闭的socket，即根本不仅让time_wait。
		占用的资源：
			time_wait期间，socket并没有被关闭，因此socket的资源都被占用。最关键的一个是端口，会导致端口被占用完，后续连接无法成功。
	14.UDP如何实现RDT，TCP采用了哪些技术。
		仅仅UDP时存在以下问题：1.传输比特受损, 2.丢包, 3.乱序。但其实UDP带了差错校验的能力。
		# UDP实现RDT
			1).分包
				待传输的数据可能会很长，因此传输的时候，实际上是分包，并按包传输。
			2).校验应答机制
				当接收方接收到UDP发送过来的一个包时，首先会对该包的数据进行校验，若数据正确则会发送ACK响应接收到了该包，否则直接丢弃该包不做任何处理。
			3).超时重传
				当发送方发送一个包时，会对该包进行计时，若在一定时间内没有接收到该包的ACK那么就会重传该包。
			4).序号机制
				包会以不同的顺序到达接收端，因此为了保证数据顺序需要在包中添加包序号。
			5).滑动窗口
				发送一个包等待ACK或者超时后才会继续发送，这样的称为停等协议。很明显，停等协议太过简单，传输效率低下，此时可以采用滑动窗口的方式来发送。
				发送方维护一个滑动窗口，主要用于按顺序快速发送窗口内的数据，不做等待。也可以用于对发送方的发送速度进行限制，比如调节滑动窗口的大小来加快发送或是抑制。
				滑动窗口通常会配合两种协议来使用：
					a).GBN
						即回退N步。意思是滑动窗口中维护的包分了两种：已经发送但是未确认 和 未发送。当窗口中的第一个包超时后，就会将窗口中的已经发送但是未确认的包重新发送。
						当滑动窗口的第一个包的ack在时间内收到，则窗口滑动。
					b).选择重传
						GBN会重发已经发送过的包，而这些包或许已经被发送方接收到了ACK。
						选择重传，会在某个包的ACK超时后将该包重新发送。选择重传的方案里面，接收方也会维护一个窗口。
						对于发送方而言，当滑动窗口的第一个包的ack在时间内收到，则窗口移动，并且要移动直到下一个未收到ACK或者未发送包的位置。
						对于接收方而言，当滑动窗口的第一个包接收到并且正确，则窗口移动，要移动到下一个未接收到的位置。
					在TCP中采用的是经过修改的选择重传。简而言之，
					一方面 TCP收到某个包以后，判断是否乱序，若没有乱序则直接返回该包的ACK，若乱序则按顺序的最后一个包的ACK进行返回。这样主要是用来提供冗余ACK，以便发送端进行快速重传。
					另一方面 并且TCP是累计确认的，即接收方收到的ACK，可以确保该ACK包序号之前的包，都被接收方接收到了。
		# TCP采用的技术
			1).校验应答
				当接收方接收到了某个包的ACK，则会判断已经连续的最后一个接收到的包，发送该包的ACK。这样主要是提供了累计确认。
			2).超时重传
				当某个包的ACK接收超时，则进行重传。
			3).快速重传
				当检验到3个冗余ACK包，则不等ACK包中所请求的包超时，直接重传。
			4).累计确认
			5).面向连接
				主要体现在采用三次握手和四次挥手。
			6).滑动窗口
				主要使用在拥塞控制和流量控制，上面已做描述。
	15.网络IO模型
		首先IO操作分了两步：1).内核数据缓冲区准备好，2).进程缓冲区和内核缓冲区之间的读写。
		对于读操作：1).内核缓冲区有接收到的数据，2).内核缓冲区的数据传到进程缓冲区中。
		对于写操作：1).内核缓冲区有多余的空间，2).进程缓冲区的数据写到内核缓冲区中。
		不同的IO模型就是在不同的时刻做不同的处理：
		a).阻塞IO
			调用IO函数，进程将会阻塞，直到内核数据缓冲区准备好 并且 进程缓冲区和内核缓冲区之间完成读写。
		b).非阻塞IO
			调用IO函数，当内核数据缓冲区数据没有准备好的时候，则立即返回一个EWOULDBLOCK。
			若内核缓冲区的数据已经准备好了，则阻塞直到进程缓冲区和内核缓冲区之间的读写完成。
		c).IO复用
			IO复用主要是指在一次IO阻塞中，将会等待多个描述符，任意一个描述符准备就绪，就会返回。
			准备就绪主要是指的该IO描述符嗦设计的内核数据缓冲区已经准备好了。
			调用select，将会等待之前注册的任意一个描述符准备就绪。
			此时再调用该描述符的IO操作，由于该描述符的内核缓冲区已经准备好了，此时会直接进行内核缓冲区和进程缓冲区之间的读写。
		d).信号驱动式IO
			通过sigaction系统调用，会直接返回，当套接字的内核缓冲区准备好后，会由内核发出SIGIO信号。只需要捕捉到该信号，就代表可以进行下一步操作了。
			通过正常的IO操作，阻塞于内核缓冲区和进程缓冲区进行读写的过程中。
		e).异步IO
			通过aio_read这样的aio操作，在内核缓冲区准备好，并且完成进程缓冲区和内核缓冲区之间的读写后，将会发送信号。
	16IO复用(select，poll，epoll)。
		select，poll，epoll都是IO复用技术，和多线程技术相比，最大的优势就是系统开销小，也不用维护这些线程。
		调用这些函数，都会首先看有没有描述字准备好，如果有则整理返回，如果没有则阻塞当有准备好的时候将会重新恢复并且检查哪些描述字准备好。
		select和poll通过线性扫描的方式来检查哪些准备好，epoll通过就绪队列来判断哪些描述字准备好。
		a).select
			int select(int maxfdp1, fd_set *readset, fd_set *writeset, fd_set *exceptset, const struct timeval *timeout)
			maxfdp1：描述字在0,1,2,...,maxfdp1-1的都会被测试。
			readset, writeset, exceptset：通过bitmap的方式进行标识监听哪个描述字的哪些事件。
			timeout：告知内核等待的描述字就绪花多少时间，可以永远等下去，可以等待一段时间，也可以直接返回。
			缺点：
				- 单个进程所打开的fd受限制，默认只能是1024。
				- 对描述字进行线性扫描，效率低下。
				- 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间传递该结构时复制开销大。
				- 每次调用select，都需要把fd集合从用户态拷贝到内核态。
		b).poll
			int poll (struct pollfd * fds, unsigned int nfds, int timeout);
			fds：指定了一个被监视的文件描述符号，可以通过传递多个结构体来指示监视多个描述符。在pollfd里面设置监听哪些事件。
			nfds：是fds的个数。
			timeout：指定poll的等待时间。
			poll和select之间没有本质区别，只是poll没有最大连接数限制，因为poll是通过链表来存储的。
			缺点：
				- 每次调用，都会导致大量的fd数组被整体复制于用户态和内核地址空间之间
				- 需要遍历文件描述符来获取已经就绪的fd，效率低下。
				- 是水平触发。
		c).epoll
			int epoll_create(int size);
				 创建一个epoll描述字，该描述字用来注册其他的待监听的描述字。
				 创建的时候要给定size参数来告诉内核监听的数目一共有多大。
			int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
				该函数用来注册/注销需要监听描述字。整个操作都是在红黑树上进行的。
				epfd：epoll描述字，在给描述字上进行注册。
				op：该函数执行的具体动作。提供了：
					- 注册(相当于往红黑树上添加一个新的fd)
					- 删除(相当于在红黑树上删除一个已存的fd)
					- 修改已注册(相当于在红黑树中定位到fd，并进行修改)
				fd：要监听的描述字。
				event：监听描述字的哪些事件。
			int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
				该函数用来等待epoll描述字上注册的fd的事件发生。
				epfd：等待该epoll描述字上的监听的fd事件发生。
				events：从内核得到事件集合。
				maxevents：这个events数组的大小，不能超过该大小。
				timeout：指定超时时间。
				返回需要处理的事件数目。
			epoll有两种工作模式：LT(水平触发，默认)和ET(边缘触发)
				- 水平触发，主要指发生事件以后，该事件除非被拉出来，否则一直保持，下次wait时会直接返回并且拿到该事件。会导致wait的反复唤醒。
				- 边缘触发，主要指发生事件以后，该事件就存在一次，不管有没有被拉出来，下次wait时除非该事件被再次触发，否则不会保存。
			优点：
				- ctl函数来将注册的fd放入内核，而不是在wait的时候将所有的fd放入内核，这样避免反复wait时有冗余的复制操作。
				- ctl函数来将注册的fd都配置一个回调函数，该回调函数会把就绪的fd放入就绪链表。这样wait时只需要看就绪链表是否有就绪的fd，避免扫描。
八、数据库
	1.mysql的数据库引擎
		1).MyISAM
			采用表锁，没有死锁危险，不具备事务功能。使用表时会将整个表的操作上读锁，可以同时读，但是不能同时写或同时读写。读操作大于更新操作时效率较高。
		2).Memory
			将数据保存在内存中。速度快，不能持久化。
		3).InnoDB
			采用行级锁，有死锁危险，采用事务管理。是mysql默认使用的数据库引擎。
	2.索引的结构和劣势
		不同的数据库与数据库引擎实现索引上有区别，对于mysql来说，Innodb的索引采用B+tree。
		1).空间劣势
			每创建一个索引，都要在磁盘中创建一份B+tree结构的索引文件，其key是索引字段，value是对应的主键。若主键字段过长，还会进一步消耗磁盘空间。
		2).增删改劣势
			当增删加一个条目时，会更新涉及到的所有索引文件的b+tree。
			当修改索引值时，也会更新对应的索引的b+tree。
		3).和主键索引的区别
			主键索引也是一个b+tree文件，key是主键，value是该条目的所有数据。普通的索引key是索引字段，value是对应的主键。
	3.crud的基本命令
		1).增: "insert into <table> (...) values (...)"
		2).删: "delete from <table> where ..."
		3).改: "update <table> set ... where ..."
		4).查: "select .. from <table> where ..."
	4.事务的acid
		1).原子性，一个事物是不可分割的最小单元，事务要么成功全部成功，要么全部失败。
		2).一致性，写进数据库与读出的一致。
		3).隔离性，通常来说，一个事务所做的操作在未提交前，对其他事务来说是不可见的。这需要隔离级别【提交读】的支持。
		4).持久性，一旦事务提交，其修改将用于保存到数据库。
	5.事务隔离级别
		1).未提交读
			其他事务未提交的修改，会反应在当前数据中，被称为【脏读】
		2).提交读
			只要其他事务提交，其修改在当前事务是可以得到的。在当前事务中不能保证读取的全一样，因此会造成【不可重复读】。
		3).可重复读
			其他事务提交了所做的修改，不会反应到当前事务中，避免了【不可重复读】。但是其他事务添加的数据会反应到当前事务中，因此会幻读。
		4).可串行化
			事务的操作完全串行化，当开了一个事务时，就不能开其他事务了。其他事务会阻塞到当前事务提交。
	6.查询优化
		0.不要在满足查询条件的查询范围比较大的情况下使用索引,不适合键值较少的列（重复数据较多的列）。
		1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
		2.尽量避免NULL：应该指定列为NOT NULL，除非你想存储NULL。在MySQL中，含有空值的列很难进行查询优化。因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值。
		4.前导模糊查询不能利用索引(like '%XX'或者like '%XX%')
		5.MySQL主要提供2种方式的索引：B-Tree索引，Hash索引。哈希索引只能做等于查找,B树支持范围查找。
		6.在创建复合索引时， 应该仔细考虑列的顺序。对索引中的所有列执行搜索或仅对前几列执行搜索时，复合索引非常有用；仅对后面的任意列执行搜索时，复合索引则没有用处。
		8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where num/2=100应改为:select id from t where num=100*2
		11.应尽可能的让字段顺序与索引顺序相一致。
		14.并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。
		15. 索引并不是越多越好，索引固然可 以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。
		17.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。
		18.尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。
		20.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。
		21.避免频繁创建和删除临时表，以减少系统表资源的消耗。
		22.临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。
		23.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。
		24.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。
		29.尽量避免大事务操作，提高系统并发能力。
		30.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。
	7.sql文(group by ， order by ， distinct ， is Null ， join...)
	8.分布式mysql，主从mysql
		分布式部署mysql的主要目的是为了提升性能和高可用。
		提升性能主要是利用【读写分离】技术来缓解读的压力，对于写的压力需要采用分区技术。
		高可用主要是利用【双master】技术。
		1).读写分离
			将主数据(master)备份多个从数据库(slave)。由master接收客户端的请求，并通过负载均衡将读请求交给slave完成。若是写请求则将请求的语句写入二进制日志，并更新master。
			一致性问题：由于读写分离，需要将更新的数据传给slave来保证一致性。
				- 同步，master的更新操作会等待更新所有的slave，所有的slave都保持同步后master才会返回客户端。redis的一致性解决方案。
				- 异步，master的更新操作不会等待更新slave，而是另开一个后台进程将更新操作交给slave。主从mysql的默认方案。
				- 半异步，master的更新操作会去更新一个slave，该slave同步后便返回客户端，不等待其他slave。类似zookeeper的一致性解决方案，只不过zookeeper是等待半数结点以上的同步。
				异步和半异步，都会造成slave滞后于master的数据，客户端需要进行额外的操作来保证从slave取出的数据是最新的。
				比如zookeeper是客户端发送sync指令要求所连接的slave同步到master的状态。
				mysql也是和zookeeper类似的同步机制：客户端获得数据库当前的binlog位置(通俗理解就是最新的更新操作编号)，在读取slave时会等待slave已经到了binlog的位置。
				由于master-slave的异步更新，对于客户端读取实时的数据造成了一些困难，常用的处理策略有：
					# 从业务上降低客户端对于数据实时性的要求的基础上，对于绕不开的事实读取，就通过获得master数据库当前binlog位置，来使slave在到达binlog时才读取slave的数据。
					# 将读请求分发到状态较新的slave上。
		2).高可用
			有【热备份】和【双master】的高可用方案，一般采用双maser。双maser又分两种：
				- active-active:
					这样的方案有利于分割地理位置不同的区域，不同的区域由不同的master提供服务，而master之间会随时保持同步。
					这样的方案比较严重的缺陷是：两个master更新相同的字段会造成冲突，并且两个master不一致的时候会造成崩溃。
				- active-passive:
					这类方案类似hdfs的namenode高可用方案，有两个master，一个master是活跃的，一个是备份的。
					两个master同步，一般会通过master的操作更新备份的master，或是将数据存放在共享磁盘空间中。
					这样的方案可能会出现split-brain的问题，需要kill掉原active。
	9.分区表
		分区表是一种粗粒度,简易的索引策略,适用于大数据的过滤场景。
	10.来自客户端大量的修改数据库的请求，数据库的修改也是大量条目的
		数据库读写分离+水平拆分+垂直拆分
		- 读写分离
			主要是减轻读压力。使用master-slave的结构，由master接收所有的请求，将都请求转发给slave，由slave执行。
			对于写请求，将写入master，而后master将异步更新slave。
		- 垂直拆分
			读写压力都能减轻。主要是分析业务，将相对之间独立的表给拆分开来放到不同的数据库主机上，这样由不同的数据库主机来处理不同的业务。
			主要是需要注意，轻微依赖的表也可以分开到不同的数据库主机上，由于仍然存在以来，因此存在跨数据库主机查询的问题。
		- 水平拆分
			读写压力都能减轻，但主要是减轻数据量过大时的写压力。主要是将数据量过大的表数据，保存到多个数据库主机上。更具体说就是表结构不变，但是数据拆分到不同主机上存储。
			当单个主机上存储过多数据，会导致btree过深，调整树将会花费更多时间。
			通过水平拆分，缩减表中的数据项，可以节约树操作。另一方面，读写操作都将会负载均衡到各个主机上去，因此读写压力也会降低。
			水平拆分存在主键不能按传统方式递增的问题，可以将表的主键值放在redis中，交由它进行递增。数据库主机的确定可以通过sid+hash的机制，将指定sid的数据放到某个主机上。		
	11.mysql锁：
		页级:引擎 BDB。
		表级:引擎 MyISAM ， 理解为锁住整个表，可以同时读，写不行
		行级:引擎 INNODB ， 单独的一行记录加锁
		表级，直接锁定整张表，在你锁定期间，其它进程无法对该表进行写操作。如果你是写锁，则其它进程则读也不允许
		行级, 仅对指定的记录进行加锁，这样其它进程还是可以对同一个表中的其它记录进行操作。
		页级，表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录		
	12.Exists与In效率分析
		In:是把外表和内表做Hash 连接，而exists 是对外表作loop 循环，每次loop循环再对内表进行查询。
		   当查询两个表的大小相当时，用In 和 exists差别不大。
		   如果两个表中一个表较小，一个表较大，那么子查询表大的用exists,子查询表小的用In，效率会高的。
           也就是说 IN适合于外表大而内表小的情况；EXISTS适合于外表小而内表大的情况，这样效率会高的
	13.Not in 和Not Exists 的 效率
       如果查询语句使用了Not In,那么内外表全部进行扫描，没有乃至索引
       Not Exist用到子表中的索引进行查询，所以无论两个表中哪个表大，Not exists 都要比Not in 要快
		   
		
九、分布式与网络编程
	1.redis
		1).redis应用场景
			共享session
			ip防刷
		2).redis和sql的区别
	2.nginx
		1).支持的负载均衡算法
		2).节点宕机处理
			a).不含nginx服务的节点宕机
				nginx有健康监测机制，而该机制又有3种。
				最简单的一种是：每当一个请求到来，会转发到一个处理节点，若该节点达到默认超出时间未响应，则向另一台处理节点转发。默认超时时间是1分钟。
			b).nginx服务的节点宕机
				nginx自己不能处理，需要使用keepalived才能配置为高可用nginx服务器。
				nginx+keepalived的工作模式类似hdfs的高可用工作模式，是一种active-standby模式。也就是由两台nginx提供负载均衡服务，但是任一时刻下只有一台提供服务，另一台作为备份。
				这种模式也叫双机热备份。
		3).nginx是多线程还是单线程
			nginx会按需同时运行多个进程，一个主进程和多个工作进程，配置了缓存时还会有缓存加载进程。nginx主要通过共享内存进行进程间通信。
			工作方式上nginx分为单工作进程 和 多工作进程。
			单工作进程是一个主进程和一个工作进程，工作进程是单线程的，这是nginx默认方案。本质就是nio的方式。
			多工作进程是一个主进程和多个工作进程，每个工作进程可以是多线程的。
	3.负载均衡算法
		1).轮询法
			将请求按顺序的分配到节点上，不关心节点的连接数和负载情况。
		2).随机法
			将每次请求到来生成要给随机数，然后按随机数将请求分配到节点上。总体来说和轮询法效果差不多。
		3).源地址hash法
			均衡器获得请求的ip地址，并生产ip地址的hash，将hash取模得到后的值作为其对应的连接节点。ip不变时每次映射到同一个节点进行处理，也没有session共享的问题。
		4).最少连接法
			均衡器记录目前所有活跃的连接，把下一个新请求发送给含有最少连接数的节点。不同的节点性能不同，因此连接数其实并不能真实反应节点的负载压力。
		5).最快响应法
			均衡器记录每个节点的网络响应时间，将下一个新请求发送给响应时间最短的节点。这种方法要求均衡器主动探测各节点状态。
		6).加权轮询法
			均衡器初始化时按照各节点的权值来生成一个序列，权值大的节点在序列中出现的次数对应较多，当请求来时便是在这个序列中进行轮询来选择处理的节点。
	4.RPC原理
	　1.调用客户端句柄；执行传送参数
	　　2.调用本地系统内核发送网络消息
	　　3.消息传送到远程主机
	　　4.服务器句柄得到消息并取得参数
	　　5.执行远程过程
	　　6.执行的过程将结果返回服务器句柄
	　　7.服务器句柄返回结果，调用远程系统内核
	　　8.消息传回本地主机
	　　9.客户句柄由内核接收消息
	　　10.客户接收句柄返回的数据
	5.RPC与RMI的区别与联系
	（1）RPC 跨语言，而 RMI只支持Java。
	（2）RMI 调用远程对象方法，允许方法返回 Java 对象以及基本数据类型，而RPC 不支持对象的概念，传送到 RPC 服务的消息由外部数据表示 (External Data Representation, XDR) 语言表示，
	    这种语言抽象了字节序类和数据类型结构之间的差异。只有由 XDR 定义的数据类型才能被传递， 可以说 RMI 是面向对象方式的 Java RPC 。
	（3）在方法调用上，RMI中，远程接口使每个远程方法都具有方法签名。如果一个方法在服务器上执行，但是没有相匹配的签名被添加到这个远程接口上，那么这个新方法就不能被RMI客户方所调用。
		 在RPC中，当一个请求到达RPC服务器时，这个请求就包含了一个参数集和一个文本值，通常形成“classname.methodname”的形式。这就向RPC服务器表明，被请求的方法在为 “classname”的类中，
		 名叫“methodname”。然后RPC服务器就去搜索与之相匹配的类和方法，并把它作为那种方法参数类型的输入。这里的参数类型是与RPC请求中的类型是匹配的。一旦匹配成功，这个方法就被调用了，
		 其结果被编码后返回客户方。
	5.kafka
	6.mr
		1).map任务处理
			1.1 读取输入文件内容，将文件分解为多个split(默认一个块就是一个split，这样可以节约集群的传输带宽)，解析成key、value对。对输入文件的每一行的起始偏移，解析成key、value对。每一个键值对调用一次map函数。
			1.2 写自己的逻辑，对输入的key、value处理，转换成新的key、value输出。
			1.3 对输出的key、value进行分区。
			1.4 对不同分区的数据，按照key进行排序、分组。相同key的value放到一个集合中。
			1.5 (可选)分组后的数据进行归约(combiner)，节约节点中的传输带宽。
		2).reduce任务处理
			2.1 对多个map任务的输出，按照不同的分区，通过网络copy到不同的reduce节点。
			2.2 对多个map任务的输出进行合并、排序。写reduce函数自己的逻辑，对输入的key、values处理，转换成新的key、value输出。
			2.3 把reduce的输出保存到文件中。
	7.elasticSearch
	8.cap
		数据一致性(consistency)：如果系统对一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有读操作都不能读到这个数据，对调用者而言数据具有强一致性(strong consistency) (又叫原子性 atomic、线性一致性 linearizable consistency)[5]
		服务可用性(availability)：所有读写请求在一定时间内得到响应，可终止、不会一直等待
		分区容错性(partition-tolerance)：在网络分区的情况下，被分隔的节点仍能正常对外服务
		在某时刻如果满足AP，分隔的节点同时对外服务但不能相互通信，将导致状态不一致，即不能满足C；
		如果满足CP，网络分区的情况下为达成C，请求只能一直等待，即不满足A；
		如果要满足CA，在一定时间内要达到节点状态一致，要求不能出现网络分区，则不能满足P。
十、并发编程
	1.synchronized和lock的区别
		这里的lock主要指ReentrantLock而不是jvm的lock指令。
		简单来说，ReentrantLock 和 synchronized相比具有相同的并发性和语义，除此外还包含中断锁等候和定时锁等候，即阻塞的线程在指定时间内依然无法获得锁，那么就会自动放弃该锁。
		更进一步，synchronized是在jvm层面的实现，ReentrantLock是在代码上实现的，因此无法自动释放锁，要显示的使用lock()和unlock()。高并发下，ReentrantLock的性能通常更好。
		Synchronized阻塞住的线程是按随机方式重新获得锁。
		Lock分了公平模式和非公平模式，公平模式是按上锁顺序获得锁，非公平模式是大体上也是按上锁顺序获得锁，但是如果在释放锁的时候刚好有个新线程尝试获得锁那么会由该新线程获得锁。Lock默认是非公平模式。
	2.volatile的作用
		volatile为了保障与主内存交互的原子性，并且可以取消重排序优化。因此具有可见性。
		volatile声明的变量操作，都会从主内存中取数据，并将数据同步到主内存。非volatile变量，使用的是线程内存。
	3.Java创建线程的三种方式
		1).继承Runnable接口
		2).继承Thread类
		3).通过 Callable 和 Future 创建线程
			- 通过ExecutorService提交Callable的方式(本质上这种方法并不是创建线程，而是提交任务，线程已经创建了的)
			- 通过FutureTask封装Callable，再由Thread封装FutureTask。FutureTask本质上是一个Runnable，更具体说是Runnable Future的子类。
	4.并发协调
		1).sleep()
			使当前线程（即调用该方法的线程）暂停执行一段时间，让其他线程有机会继续执行，但它并不释放对象锁。也就是说如果有synchronized同步快，
			其他线程仍然不能访问共享数据。注意该方法要捕捉异常。
		2).join()
			join()方法使调用该方法的线程在此之前执行完毕，也就是等待该方法的线程执行完毕后再往下继续执行。注意该方法也需要捕捉异常。
		3).yield()
			该方法与sleep()类似，只是不能由用户指定暂停多长时间，并且yield（）方法只能让同优先级的线程有执行的机会。
		4).wait()和notify()、notifyAll()
			wait()方法使当前线程暂停执行并释放对象锁标示，让其他线程可以进入synchronized数据块，当前线程被放入对象等待池中。当调用notify()方法后，将从对象的等待池中移走一个任意的线程并放到锁标志等待池中，
			只有锁标志等待池中线程能够获取锁标志；如果锁标志等待池中没有线程，则notify()不起作用。
	5.如何解决死锁问题
	6.SimpleDateFormat的线程安全问题
		SimpleDateFormat不是一个线程安全的类。
		当多个线程调用sdf对象的format方法，由于format方法里面有一个calendar的对象，该对象被多个线程共享，format的参数会set给calendar，而calendar在后面还会使用。
		因此会带来竞争问题。
十一、操作系统
	1.进程和线程的区别
	2.进程间如何通讯
		# 管道( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
		# 有名管道 (namedpipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
		# 信号量(semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
		# 消息队列( messagequeue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
		# 信号 (sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
		# 共享内存(shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
		# 套接字(socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。
	3.线程间如何通讯
		# 锁机制：包括互斥锁、条件变量、读写锁
			*互斥锁提供了以排他方式防止数据结构被并发修改的方法。
			*读写锁允许多个线程同时读共享数据，而对写操作是互斥的。
			*条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。
		# 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量
		# 信号机制(Signal)：类似进程间的信号处理
			线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。
	4.进程的堆栈的区别
	5.多线程的优势
		1).相比单进程的优势
			- 提升可伸缩性，采用了多线程可以充分发挥多核的优势，并且合理的多线程利用前提下，随着cpu资源的增加，吞吐量可以进一步提升。
			- 时间片轮询，将时间分配给多个线程去使用，可以提升ui的流畅程度。
		2).相比多进程的优势
			- 轻量级，因此线程的创建销毁，上下文切换的成本都远低于多进程。
			- 内存共享，因此多线程之间更容易共享内容，更容易协调工作。
	6.如何解决死锁
		1.死锁的条件：
			- 互斥：当进程占有资源时，其他进程操作资源将被阻塞。
			- 占有并等待：进程阻塞时并不会释放对资源的占有。
			- 不可抢夺：进程所占有的资源不能被其他进程抢夺。
			- 循环等待：存在一个封闭的进程资源依赖链。进程1请求进程2的R2，进程2请求进程3的R3，...，进程n请求进程1的R1。
			这4个都是必要条件，4个在一起就是死锁的充要条件。
		2.死锁预防
			主要是通过打破会产生死锁的条件来解决死锁。
			1.预先上锁
				进程开始时先把所用到的资源全部占有，占有了才开始执行进程逻辑。这样就能避免中途进程阻塞去等待资源。
				这样做效率低下：
					- 有些资源很少会用到，但是还是一直占有。
					- 进程一开始的时候会申请所有资源，所以阻塞时间较长。
					- 进程并常常不能预先知道会用到的所有资源。
			2.顺序上锁
				不同进程间对资源的请求顺序相同，进程1按顺序请求ABC，进程2也按顺序请求ABC。
			3.乐观锁
		3.死锁避免
			根据R(资源总数向量)、V(资源剩余向量)、C(Cij代表进程i对资源j的总需求)、A(Aij代表进程i已经分配到的资源j的数量)矩阵来指定死锁避免策略。
			典型的有银行家算法，即资源分配拒绝策略。
十二、安全
	1.常用加密算法
		异或加密、DES、AES、RSA、椭圆加密、混沌加密。
	2.对称加密和非对称加密
		1).对称加密
			即传统的加密方式，加密解密使用同一个密钥。DES和AES是用的较多的对称加密方案。DES现在已经不够安全了。
		2).非对称加密(密钥对加密)
			即常见的用公钥私钥的加密方法，常用的有rsa加密和椭圆加密。
			非对称加密主要使用密钥对来完成操作，公钥加密的数据可以使用私钥解密，私钥加密的数据可以使用公钥解密。使用场景:
			a).传统加密传输
				A向B发送秘密信息，B将生成密钥对并将公钥发送给A，A使用公钥进行加密，然后将加密数据发送给B。
				https就是采用这也的机制，浏览器将数据使用公钥进行加密发送给服务器，由服务器来进行解密。
			b).身份认证
				A证实B的身份，B将生成密钥对将公钥发送给A，而后由B发送到A的操作均是通过私钥加密的，A将使用公钥将解密这个信息，若无法解析则无法证实B的身份，拒绝A的数据。
				github采用的就是该机制，github是角色A，本地仓库是角色B。github会使用所有的公钥来解析本地仓库发送过去的数据，若均无法解析则拒绝本地仓库的请求。
十三、NIO
	1.NIO主要有哪些类
		1) Buffer
			Buffer抽象代表了一个有限容量的数据容器，其本质是一个数组。由指针指示了哪里存放数据以及从哪里读取数据。
			ByteBuffer buffer = new ByteBuffer.allocate(CAPACITY);
		2) Channel
			Channel的实例代表了一个与设备的连接，通过channel进输入和输出操作。对于TCP而言有两种：ServerSocketChannel和SocketChannel。
			channel可以设置为阻塞或者非阻塞：socket.configureBlocking(false);
			ServerSocketChannel在执行accept()方法时，若有连接请求在等待，则返回SocketChannel实例。
		3) Selector
			Selector的实例中可以注册多个Channel的实例，当Channel的实例有事件触发时，将会在Selector中进行记录。channel.register(selector, event);
			通过selector.select()方法，可以返回已有记录的Channel与其对应的事件。
			可以注册的事件有:
				- SelectionKey.OP_ACCEPT
					这个是ServerSocketChannel的事件。当serverChannel接收到客户端socket的连接请求时，将会触发该事件。
				- SelectionKey.OP_READ
					这个是SocketChannel的事件，当socket的读缓冲区中存在数据时，将会触发该事件。
				- SelectionKey.OP_WRITE
					这个是SocketChannel的事件按，当socket的写缓冲区没有满时，将会触发改事件。
			与Selector配合使用的还有SelectionKey类，该类封装了Channel和一个事件。Selector的select()方法将会返回一组SelectiongKey，里面有发生事件的Channel及其事件本身。
	2.举出一个NIO的使用流程范例
		nio主要在服务器端使用:
			private void service() throws Exception{
				Selector selector = Selector.open();
				
				ServerSocketChannel serverChannel = ServerSocketChannel.open();
				serverChannel.socket().bind(new InetSocketAddress(port));
				serverChannel.configureBlocking(false);
				serverChannel.register(selector, SelectionKey.OP_ACCEPT);
				
				System.out.println("service start...");
				while(true){
					if(selector.select(100) == 0){continue;}		//避免永久阻塞

					Iterator<SelectionKey> keyIter = selector.selectedKeys().iterator();
					while(keyIter.hasNext()){
						SelectionKey key = keyIter.next();
						if(key.isAcceptable()){
							handleAccept(key);
						}else if(key.isReadable()){	
							handleRead(key);
						}else if(key.isWritable()){
							handleWrite(key);
						}
						keyIter.remove();
					}
				}
			}

			protected void handleAccept(SelectionKey key) throws IOException{
				SocketChannel clntSocket = ((ServerSocketChannel)key.channel()).accept();
				clntSocket.configureBlocking(false);
				clntSocket.register(key.selector(), SelectionKey.OP_READ, new ByteArrayOutputStream());	//注册读客户端socket的事件
			}

十五、其他
	1.服务器优化
		1).缓存机制
			缓存机制符合分形几何学，即每个缓存系统的局部都又可以看成一个缓存系统。
			整体： 浏览器 <---> 前端cache <---> 服务器
			mysql局部 : 请求 <---> innodb_buffer_prol存放热点数据 <---> MySQL内部数据
			mysql内部 : 内存 <---> L1 Cache <---> L2 Cache <---> L3 Cache <---> 硬盘
		2).负载均衡
			- 重定向进行负载均衡，简单，局部小范围使用。
			- DNS进行负载均衡，可以给一个域名配置多个ip地址，以此来进行负载均衡。当系统宕机，很难修改dns，而且不够灵活。
			- nginx反向代理，易于控制，但是nginx服务器的宕机会带来灾难性影响，并且超高并发环境下nginx服务器将成为瓶颈。
			- 多级负载均衡，设计多个nginx进行负载均衡器，而client到nginx的负载均衡是交由dns负责。
				client ---dns负载均衡---> nginx ---负载均衡---> 业务系统
			- 读写分离，数据库采用mater-slave的方式，master将读操作传递给slave，由slave负责，这本质上就是一种负载均衡。写操作在master上进行，master会将操作更新到slave。
			- 数据库水平拆分，水平拆分是将一张表的数据保存在多个服务器上，这样可以缓解update操作的压力。因为若将数据全部放在一个主机上，会导致索引的b树很深。因此update操作会带来很大的性能影响。
		3).共享资源的并发优化
			- 锁分段，根据读写的范围，将共享资源分为多个部分，每次只针对该读写的部分进行上锁。行级锁就是一种这样的机制，不用给整个表上锁。
			- 读写锁，【并发读】不上锁，【并发读写】或者【并发写】才上锁。当有读和写操作在等待时，根据读优先模式和写优先模式，选择优先进行读操作或是写操作。
			- 乐观锁，本质上就是CAS+版本号控制机制。（CAS本身就是一种乐观锁，但是需要依赖版本号才能避免ABA问题。）
		4).拆分
			垂直拆分的含义就是根据业务功能，将相对独立的模块分割到不同的服务器上。
			- 业务模块拆分，主要是将相对独立的业务拆分到不同的服务器上。
			- 数据库垂直拆分，主要是将相互独立的表拆分到不同的数据库主机上。
			- 字段拆分
			水平拆分是将一个表的连续的多条记录划分到不同的服务器上。分区表就是一种水平拆分，只是没有分布式而已。
		5).高可用
			- nginx高可用，每个nginx都应该使用备份的nginx以免宕机。
			- 数据库高可用。
			- 缓存系统高可用。
			- 业务系统高可用。（其实就是引入负载均衡）
十六、C/C++
	1.C++多态的实现方式
		通过覆盖(覆盖父类方法)、重载(方法同名，参数不同)和模板类可以实现多态。
	2.虚函数的作用和底层实现细节
		基类定义虚函数，子类可以重写该函数；在派生类中对基类定义的虚函数进行重写时，需要再派生类中声明该方法为虚方法。
		每个对象实例化的时候，都会有一个隐藏成员，隐藏成员中保存了一个指向函数地址数组的指针，称为虚函数指针：vptr。数组被称为虚函数表。
		虚函数表中存放着该对象的所有虚函数的函数入口。
		更进一步，父类和子类都有这个虚函数，子类对该虚函数进行了重写，也因此子类new出的对象的vptr里面是子类的虚函数入口，而非父类。
	3.继承类调用构造函数和析构函数顺序
		首先执行父类构造函数，再执行子类构造函数。
		释放的时候首先执行子类析构函数，再执行父类析构函数。
	4.析构函数什么时候定义为虚函数
		Parent *a = new Child();
		当Parent里面，析构函数为虚函数时，delete a会首先执行Child里面的析构函数，再执行父类的析构函数。
		若析构函数为非虚函数，那么delete a会直接执行Parent的析构函数，不管Child的析构函数。
		析构函数主要用于类中变量的堆内存释放等操作，因此若Child中有申请空间的操作，那么Child必须有析构函数负责内存的释放。因此需要声明为虚函数。
		Child中没有内存相关操作的时候，就不用将析构函数声明为虚函数，这样可以提升效率。
	5.引用和指针的区别
		引用在实现上其实就是指针，只是杜绝了取值操作。其实引用就相当于是某个内存区域的句柄，任何对引用的操作都会基于该内存区域。
		引用在初始化完成以后，是不可以修改的。也就是说引用某个内存区域以后，不能再引用别的内存区域。
	6.new和malloc的异同
		相同点：new和malloc都可以用来分配空间。
		不同点：
			- 申请的内存所在位置
				malloc从堆上分配动态内存。
				new操作符从free store上为对象动态分配内存。
				free store是一个抽象的概念。是对所有存储区域的一个抽象。free store具体是什么内存，取决于对operator new的实现。
			- 返回类型安全性
				new操作符内存分配成功时，返回的是对象类型指针，而malloc返回的是void*。因此new的返回值更安全。
			- 内存分配失败时的返回值
				new内存分配失败，抛出bac_alloc异常。malloc分配内存失败返回null。
			- 是否需要指定内存大小
				new不用指定内存大小，malloc需要指定大小。
			- 是否会调用构造函数/析构函数
				采用new时会经历3个步骤：
					a).调用operator new函数分配一块足够大的，原始的，未命名的内存空间以便存储特定类型的对象。
					b).编译器运行相应的构造函数以构造对象，并传入初始值。
					c).对象构造完成，返回一个指向该对象的指针。
				采用delete时会经历2个步骤：
					a).调用对象的析构函数
					b).调用operator delete来释放内存空间。
				malloc并不会调用构造函数，free也不会调用析构函数。
			- new与malloc的相互调用
				new里面的new operator可以基于malloc来进行实现，但是malloc不能基于new进行实现。
				operator delete也可以基于free来进行实现。
			- 重新分配内存
				malloc分配内存后，若当时分配的空间不足够用了，可以通过realloc进行内存重新分配。
				realloc会先判断指针所指向的内存是否有足够的连续空间，如果有则原地过大内存，并返回原理的指针。
				若空间不够用，则按照指定的大小重新分配空间，并将数据拷贝到新的内存区域中去，释放原内存区域，返回新内存区域的指针。
				new不支持这样的操作。
			- 内存不足
				内存不足时，operator new会调用一个用户指定的错误处理函数。
	7.结构体内存对其方式
	8.大端和小端
		0x1234(高字节<->低字节)
		小端：低字节->低地址  0x34(低地址) 0x12(高地址)
		大端: 高字节->低地址  0x12(低地址) 0x34(高地址)
	9.进程内存映射
		内核虚拟存储器(内核)
		用户栈(向下增长)
		共享库的存储器映射区域(.so或.dll)
		堆(malloc，向上增长)
		读写数据(.bss-未初始化的全局数据 .data-已经初始化的全局数据或static)
		只读数据(.init-初始化例程 .text-代码块 .rodata-常量(比如字符串常量，const))